{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "# Notebook for converting native Tensorflow frozen graph to TF-TRT model\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.tensorrt as trt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(model_file):\n",
    "  graph = tf.Graph()\n",
    "  graph_def = tf.GraphDef()\n",
    "\n",
    "  with open(model_file, \"rb\") as f:\n",
    "    graph_def.ParseFromString(f.read())\n",
    "  with graph.as_default():\n",
    "    tf.import_graph_def(graph_def)\n",
    "\n",
    "  return graph\n",
    "\n",
    "def load_graph_def(model_file):  \n",
    "  graph_def = tf.GraphDef()\n",
    "\n",
    "  with open(model_file, \"rb\") as f:\n",
    "    graph_def.ParseFromString(f.read())\n",
    "  \n",
    "  return graph_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tensor_from_image_file(file_name,\n",
    "                                input_height=299,\n",
    "                                input_width=299,\n",
    "                                input_mean=0,\n",
    "                                input_std=255):\n",
    "  input_name = \"file_reader\"\n",
    "  output_name = \"normalized\"\n",
    "  file_reader = tf.read_file(file_name, input_name)\n",
    "  if file_name.endswith(\".png\"):\n",
    "    image_reader = tf.image.decode_png(\n",
    "        file_reader, channels=3, name=\"png_reader\")\n",
    "  elif file_name.endswith(\".gif\"):\n",
    "    image_reader = tf.squeeze(\n",
    "        tf.image.decode_gif(file_reader, name=\"gif_reader\"))\n",
    "  elif file_name.endswith(\".bmp\"):\n",
    "    image_reader = tf.image.decode_bmp(file_reader, name=\"bmp_reader\")\n",
    "  else:\n",
    "    image_reader = tf.image.decode_jpeg(\n",
    "        file_reader, channels=3, name=\"jpeg_reader\")\n",
    "  float_caster = tf.cast(image_reader, tf.float32)\n",
    "  dims_expander = tf.expand_dims(float_caster, 0)\n",
    "  resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
    "  normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
    "  sess = tf.compat.v1.Session()\n",
    "  result = sess.run(normalized)\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_file):\n",
    "  label = []\n",
    "  proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
    "  for l in proto_as_ascii_lines:\n",
    "    label.append(l.rstrip())\n",
    "  return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./data/grace_hopper.jpg\"\n",
    "model_file = \"./data/inception_v3_2016_08_28_frozen.pb\"\n",
    "label_file = \"./data/imagenet_slim_labels.txt\"\n",
    "input_height = 299\n",
    "input_width = 299\n",
    "input_mean = 0\n",
    "input_std = 255\n",
    "input_layer = \"input\"\n",
    "output_layer = \"InceptionV3/Predictions/Reshape_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = load_graph(model_file)\n",
    "    \n",
    "t = read_tensor_from_image_file(\n",
    "      file_name,\n",
    "      input_height=input_height,\n",
    "      input_width=input_width,\n",
    "      input_mean=input_mean,\n",
    "      input_std=input_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "military uniform 0.8343052\n",
      "mortarboard 0.021869471\n",
      "academic gown 0.010358049\n",
      "pickelhaube 0.00800826\n",
      "bulletproof vest 0.0053509204\n"
     ]
    }
   ],
   "source": [
    "input_name = \"import/\" + input_layer\n",
    "output_name = \"import/\" + output_layer\n",
    "input_operation = graph.get_operation_by_name(input_name)\n",
    "output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "with tf.compat.v1.Session(graph=graph) as sess:\n",
    "    results = sess.run(output_operation.outputs[0], {\n",
    "        input_operation.outputs[0]: t\n",
    "    })\n",
    "results = np.squeeze(results)\n",
    "\n",
    "top_k = results.argsort()[-5:][::-1]\n",
    "labels = load_labels(label_file)\n",
    "for i in top_k:\n",
    "    print(labels[i], results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark native TensorFlow model...\n",
      "Step 0:  7.9ms\n",
      "Step 50:  8.0ms\n",
      "Step 100:  8.0ms\n",
      "Step 150:  8.0ms\n",
      "Step 200:  8.3ms\n",
      "Step 250:  8.2ms\n",
      "Step 300:  8.0ms\n",
      "Step 350:  8.0ms\n",
      "Step 400:  8.1ms\n",
      "Step 450:  7.9ms\n",
      "Step 500:  8.1ms\n",
      "Step 550:  8.1ms\n",
      "Step 600:  8.2ms\n",
      "Step 650:  8.2ms\n",
      "Step 700:  8.0ms\n",
      "Step 750:  8.0ms\n",
      "Step 800:  8.1ms\n",
      "Step 850:  7.9ms\n",
      "Step 900:  8.0ms\n",
      "Step 950:  8.0ms\n",
      "Throughput: 124 images/s\n"
     ]
    }
   ],
   "source": [
    "# Benchmark native TensorFlow model\n",
    "\n",
    "N_warmup_run = 50\n",
    "N_run = 1000\n",
    "elapsed_time = []\n",
    "BATCH_SIZE = 1 \n",
    "\n",
    "print(\"Benchmark native TensorFlow model...\")\n",
    "with tf.compat.v1.Session(graph=graph) as sess:\n",
    "    for i in range(N_warmup_run):\n",
    "        results = sess.run(output_operation.outputs[0], {\n",
    "                           input_operation.outputs[0]: t\n",
    "                           })\n",
    "\n",
    "    for i in range(N_run):\n",
    "      start_time = time.time()\n",
    "      results = sess.run(output_operation.outputs[0], {\n",
    "                           input_operation.outputs[0]: t\n",
    "                           })\n",
    "      end_time = time.time()\n",
    "      elapsed_time = np.append(elapsed_time, end_time - start_time)\n",
    "      if i % 50 == 0:\n",
    "        print('Step {}: {:4.1f}ms'.format(i, (elapsed_time[-50:].mean()) * 1000))\n",
    "\n",
    "    print('Throughput: {:.0f} images/s'.format(N_run * batch_size / elapsed_time.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "\n",
    "graph_def = load_graph_def(model_file)\n",
    "    \n",
    "trt_fp32_graph = trt.create_inference_graph(\n",
    "    input_graph_def=graph_def,\n",
    "    outputs=['InceptionV3/Predictions/Reshape_1'],\n",
    "    max_batch_size=BATCH_SIZE,\n",
    "    precision_mode=\"FP32\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.gfile.GFile('./data/inception_v3_2016_08_28_frozen_tftrt_fp32.pb', 'wb') as f:\n",
    "    f.write(trt_fp32_graph.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "military uniform 0.8343058\n",
      "mortarboard 0.021869456\n",
      "academic gown 0.010358036\n",
      "pickelhaube 0.008008182\n",
      "bulletproof vest 0.0053508864\n"
     ]
    }
   ],
   "source": [
    "# Testing TF-TRT Model\n",
    "graph = load_graph('./data/inception_v3_2016_08_28_frozen_tftrt_fp32.pb')\n",
    "\n",
    "input_name = \"import/\" + input_layer\n",
    "output_name = \"import/\" + output_layer\n",
    "input_operation = graph.get_operation_by_name(input_name)\n",
    "output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "with tf.compat.v1.Session(graph=graph) as sess:\n",
    "    results = sess.run(output_operation.outputs[0], {\n",
    "        input_operation.outputs[0]: t\n",
    "    })\n",
    "results = np.squeeze(results)\n",
    "\n",
    "top_k = results.argsort()[-5:][::-1]\n",
    "labels = load_labels(label_file)\n",
    "for i in top_k:\n",
    "    print(labels[i], results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark TF-TRT model...\n",
      "Step 0:  5.5ms\n",
      "Step 50:  5.4ms\n",
      "Step 100:  5.3ms\n",
      "Step 150:  5.3ms\n",
      "Step 200:  5.2ms\n",
      "Step 250:  5.2ms\n",
      "Step 300:  5.2ms\n",
      "Step 350:  5.3ms\n",
      "Step 400:  5.3ms\n",
      "Step 450:  5.3ms\n",
      "Step 500:  5.3ms\n",
      "Step 550:  5.3ms\n",
      "Step 600:  5.3ms\n",
      "Step 650:  5.3ms\n",
      "Step 700:  5.2ms\n",
      "Step 750:  5.3ms\n",
      "Step 800:  5.3ms\n",
      "Step 850:  5.3ms\n",
      "Step 900:  5.2ms\n",
      "Step 950:  5.3ms\n",
      "Throughput: 190 images/s\n"
     ]
    }
   ],
   "source": [
    "# Benchmark TF-TRT model\n",
    "\n",
    "N_warmup_run = 50\n",
    "N_run = 1000\n",
    "elapsed_time = []\n",
    "batch_size = 1 \n",
    "\n",
    "print(\"Benchmark TF-TRT model...\")\n",
    "with tf.compat.v1.Session(graph=graph) as sess:\n",
    "    for i in range(N_warmup_run):\n",
    "        results = sess.run(output_operation.outputs[0], {\n",
    "                           input_operation.outputs[0]: t\n",
    "                           })\n",
    "\n",
    "    for i in range(N_run):\n",
    "      start_time = time.time()\n",
    "      results = sess.run(output_operation.outputs[0], {\n",
    "                           input_operation.outputs[0]: t\n",
    "                           })\n",
    "      end_time = time.time()\n",
    "      elapsed_time = np.append(elapsed_time, end_time - start_time)\n",
    "      if i % 50 == 0:\n",
    "        print('Step {}: {:4.1f}ms'.format(i, (elapsed_time[-50:].mean()) * 1000))\n",
    "\n",
    "    print('Throughput: {:.0f} images/s'.format(N_run * BATCH_SIZE / elapsed_time.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
