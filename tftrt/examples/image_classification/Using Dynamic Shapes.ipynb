{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tensorflow/tensorrt/blob/r2.0/tftrt/examples/image_classification/TFv2-TF-TRT-inference-from-Keras-saved-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dR1W9kv7IPhE"
   },
   "outputs": [],
   "source": [
    "# Copyright 2019 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yb3TdMZAkVNq"
   },
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# TensorFlow-TRT: Using Dynamic Shapes\n",
    "\n",
    "\n",
    "## Introduction\n",
    "The NVIDIA TensorRT is a C++ library that facilitates high performance inference on NVIDIA graphics processing units (GPUs). TensorRT takes a trained network, which consists of a network definition and a set of trained parameters, and produces a highly optimized runtime engine which performs inference for that network. \n",
    "\n",
    "TensorFlow™ integration with TensorRT™ (TF-TRT) optimizes and executes compatible subgraphs, allowing TensorFlow to execute the remaining graph. While you can still use TensorFlow's wide and flexible feature set, TensorRT will parse the model and apply optimizations to the portions of the graph wherever possible.\n",
    "\n",
    "This notebook has the following sections:\n",
    "1. [TL;DR Explanation](#1)\n",
    "1. [Installing and checking dependencies](#2)\n",
    "1. [Setting up the model](#3)\n",
    "1. [Working with Dynamic shapes in TF-TRT](#4)\n",
    "\n",
    "## TL;DR Explanation\n",
    "\n",
    "## Installing and checking dependencies\n",
    "\n",
    "### GPU\n",
    "\n",
    "This demo will work on any NVIDIA GPU with CUDA cores, though for improved FP16 and INT8 inference, a Volta, Turing, Ampere or newer generation GPU with Tensor cores is desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Fg4x4aomCY4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr  6 21:56:19 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA Graphics...  On   | 00000000:01:00.0 Off |                    0 |\r\n",
      "| 41%   60C    P0   107W / 200W |      0MiB / 47681MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LG4IBNn-2PWY"
   },
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (9.0.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (4.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.21.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.0)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (6.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from setuptools-scm>=4->matplotlib) (59.4.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from setuptools-scm>=4->matplotlib) (2.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pillow matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nWYufTjPCMgW"
   },
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yyzwxjlm37jx"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "v0mfnfqg3ned",
    "outputId": "11c043a0-b8e5-49e2-f907-5f1372c92a68",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.8.0\n",
      "TensorRT version: \n",
      "ii  libnvinfer-bin                    8.2.3-1+cuda11.4                  amd64        TensorRT binaries\n",
      "ii  libnvinfer-dev                    8.2.3-1+cuda11.4                  amd64        TensorRT development libraries and headers\n",
      "ii  libnvinfer-plugin-dev             8.2.3-1+cuda11.4                  amd64        TensorRT plugin libraries and headers\n",
      "ii  libnvinfer-plugin8                8.2.3-1+cuda11.4                  amd64        TensorRT plugin library\n",
      "ii  libnvinfer8                       8.2.3-1+cuda11.4                  amd64        TensorRT runtime libraries\n"
     ]
    }
   ],
   "source": [
    " print(\"Tensorflow version: \", tf.version.VERSION)\n",
    "\n",
    "# check TensorRT version\n",
    "print(\"TensorRT version: \")\n",
    "!dpkg -l | grep nvinfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9U8b2394CZRu"
   },
   "source": [
    "A successfull TensorRT installation looks like:\n",
    "\n",
    "```\n",
    "TensorRT version: \n",
    "ii  libnvinfer5   5.1.5-1+cuda10.1   amd64        TensorRT runtime libraries\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SeekwaXj4CbI"
   },
   "source": [
    "### Check Tensor core GPU\n",
    "The below code check whether a Tensor-core GPU is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VHLld1VNkVOa",
    "outputId": "a0d2b13c-fe62-476c-9589-190bdcfff233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Core GPU Present: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 21:56:24.181641: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-06 21:56:24.315566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:24.377563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:24.377832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:24.766371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:24.766617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:24.766782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:24.766917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 45269 MB memory:  -> device: 0, name: NVIDIA Graphics Device, pci bus id: 0000:01:00.0, compute capability: 8.0\n",
      "2022-04-06 21:56:24.768017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:24.768193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:24.768347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:24.768527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:24.768688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:24.768800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 45269 MB memory:  -> device: 0, name: NVIDIA Graphics Device, pci bus id: 0000:01:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def check_tensor_core_gpu_present():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    for line in local_device_protos:\n",
    "        if \"compute capability\" in str(line):\n",
    "            compute_capability = float(line.physical_device_desc.split(\"compute capability: \")[-1])\n",
    "            if compute_capability>=7.0:\n",
    "                return True\n",
    "    \n",
    "print(\"Tensor Core GPU Present:\", check_tensor_core_gpu_present())\n",
    "tensor_core_gpu = check_tensor_core_gpu_present()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xeV4r2YTkVO1"
   },
   "source": [
    "## Model\n",
    "\n",
    "We next download and test a ResNet-50 pre-trained model from the Keras model zoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "WwRBOikEkVO3",
    "outputId": "2d63bc46-8bac-492f-b519-9ae5f19176bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 21:56:29.645825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:29.646105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:29.646262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:29.646594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:29.646755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:29.646904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:29.647105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:29.647261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:56:29.647416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45269 MB memory:  -> device: 0, name: NVIDIA Graphics Device, pci bus id: 0000:01:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, let's quick take a look at the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "WxlUF3rlkVPH",
    "outputId": "9f3864e7-f211-4c06-d2d2-585c1a477e34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 21:56:39.020238: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet50_saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "model.save('resnet50_saved_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "colab_type": "code",
    "id": "RBu2RKs6kVPP",
    "outputId": "8e063261-7efb-47fd-fa6c-1bb5076d418c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['input_1'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 224, 224, 3)\n",
      "        name: serving_default_input_1:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['predictions'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1000)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "Concrete Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_1: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_1: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_1: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_1: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_1: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --all --dir resnet50_saved_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XrL3FEcdkVPA"
   },
   "source": [
    "TF-TRT takes input as aTensorFlow saved model, therefore, we re-export the Keras model as a TF saved model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qBQwBvlNm-J8"
   },
   "source": [
    "### Benchmarking Inference with native TF2.0 saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CGc-dC6DvwRP",
    "outputId": "e0a22e05-f4fe-47b6-93e8-2b806bf7098a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched_input shape:  (8, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "batched_input = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n",
    "batched_input = tf.constant(batched_input)\n",
    "print('batched_input shape: ', batched_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rFBV6hQR7N3z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: 43.1ms\n",
      "Step 50: 44.7ms\n",
      "Step 100: 43.9ms\n",
      "Step 150: 43.7ms\n",
      "Step 200: 42.5ms\n",
      "Step 250: 53.5ms\n",
      "Step 300: 45.5ms\n",
      "Step 350: 44.8ms\n",
      "Step 400: 44.0ms\n",
      "Step 450: 43.1ms\n",
      "Step 500: 42.5ms\n",
      "Step 550: 42.0ms\n",
      "Step 600: 41.8ms\n",
      "Step 650: 41.7ms\n",
      "Step 700: 41.7ms\n",
      "Step 750: 41.5ms\n",
      "Step 800: 41.6ms\n",
      "Step 850: 41.5ms\n",
      "Step 900: 41.4ms\n",
      "Step 950: 41.4ms\n",
      "Throughput: 185 images/s\n"
     ]
    }
   ],
   "source": [
    "# Benchmarking throughput\n",
    "N_warmup_run = 50\n",
    "N_run = 1000\n",
    "elapsed_time = []\n",
    "\n",
    "for i in range(N_warmup_run):\n",
    "  preds = model.predict(batched_input)\n",
    "\n",
    "for i in range(N_run):\n",
    "  start_time = time.time()\n",
    "  preds = model.predict(batched_input)\n",
    "  end_time = time.time()\n",
    "  elapsed_time = np.append(elapsed_time, end_time - start_time)\n",
    "  if i % 50 == 0:\n",
    "    print('Step {}: {:4.1f}ms'.format(i, (elapsed_time[-50:].mean()) * 1000))\n",
    "\n",
    "print('Throughput: {:.0f} images/s'.format(N_run * batch_size / elapsed_time.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vC_RN0BAkVPy"
   },
   "source": [
    "### TF-TRT FP32 model\n",
    "\n",
    "We first convert the TF native FP32 model to a TF-TRT FP32 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "0eLImSJ-kVPz",
    "outputId": "e2c353c7-8e4b-49aa-ab97-f4d82797d4d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to TF-TRT FP32...\n",
      "INFO:tensorflow:Linked TensorRT version: (8, 2, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (8, 2, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 21:57:54.648891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:57:54.649087: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-04-06 21:57:54.649165: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-04-06 21:57:54.649568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:57:54.649761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:57:54.649917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:57:54.662647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:57:54.662854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:57:54.662977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45269 MB memory:  -> device: 0, name: NVIDIA Graphics Device, pci bus id: 0000:01:00.0, compute capability: 8.0\n",
      "2022-04-06 21:57:54.695724: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1191] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 1202 nodes (878), 1857 edges (1533), time = 18.682ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.009ms.\n",
      "\n",
      "2022-04-06 21:57:56.387224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:57:56.387435: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-04-06 21:57:56.387516: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-04-06 21:57:56.387900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:57:56.388074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:57:56.388227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:57:56.388426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:57:56.388593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 21:57:56.388714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45269 MB memory:  -> device: 0, name: NVIDIA Graphics Device, pci bus id: 0000:01:00.0, compute capability: 8.0\n",
      "2022-04-06 21:57:56.672358: W tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:192] Calibration with FP32 or FP16 is not implemented. Falling back to use_calibration = False.Note that the default value of use_calibration is True.\n",
      "2022-04-06 21:57:56.672417: I tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:211] [TF-TRT] not using explicit QDQ mode\n",
      "2022-04-06 21:57:56.872788: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:954] \n",
      "\n",
      "################################################################################\n",
      "TensorRT unsupported/non-converted OP Report:\n",
      "\t- NoOp -> 2x\n",
      "\t- Identity -> 1x\n",
      "\t- Placeholder -> 1x\n",
      "--------------------------------------------------------------------------------\n",
      "\t- Total nonconverted OPs: 4\n",
      "\t- Total nonconverted OP Types: 3\n",
      "For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops.\n",
      "################################################################################\n",
      "\n",
      "2022-04-06 21:57:56.893764: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:1281] The environment variable TF_TRT_MAX_ALLOWED_ENGINES=20 has no effect since there are only 1 TRT Engines with  at least minimum_segment_size=3 nodes.\n",
      "2022-04-06 21:57:56.897250: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:795] Number of TensorRT candidate segments: 1\n",
      "2022-04-06 21:57:56.902809: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:909] Replaced segment 0 consisting of 500 nodes by TRTEngineOp_0_0.\n",
      "2022-04-06 21:57:56.998945: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1191] Optimization results for grappler item: tf_graph\n",
      "  model_pruner: Graph size after: 880 nodes (-322), 1535 edges (-322), time = 6.025ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.059ms.\n",
      "  layout: Graph size after: 884 nodes (4), 1539 edges (4), time = 28.833ms.\n",
      "  dependency_optimizer: Graph size after: 560 nodes (-324), 575 edges (-964), time = 9.474ms.\n",
      "  constant_folding: Graph size after: 558 nodes (-2), 573 edges (-2), time = 15.735ms.\n",
      "  common_subgraph_elimination: Graph size after: 508 nodes (-50), 573 edges (0), time = 49.07ms.\n",
      "  TensorRTOptimizer: Graph size after: 9 nodes (-499), 2 edges (-571), time = 236.259ms.\n",
      "  constant_folding: Graph size after: 3 nodes (-6), 2 edges (0), time = 0.964ms.\n",
      "Optimization results for grappler item: TRTEngineOp_0_0_native_segment\n",
      "  model_pruner: Graph size after: 450 nodes (-52), 469 edges (-52), time = 2.763ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.033ms.\n",
      "  layout: Graph size after: 450 nodes (0), 469 edges (0), time = 8.059ms.\n",
      "  dependency_optimizer: Graph size after: 450 nodes (0), 469 edges (0), time = 3.42ms.\n",
      "  constant_folding: Graph size after: 450 nodes (0), 469 edges (0), time = 8.021ms.\n",
      "  common_subgraph_elimination: Graph size after: 450 nodes (0), 469 edges (0), time = 41.591ms.\n",
      "  TensorRTOptimizer: Graph size after: 450 nodes (0), 469 edges (0), time = 0.716ms.\n",
      "  constant_folding: Graph size after: 450 nodes (0), 469 edges (0), time = 8.215ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Could not find TRTEngineOp_0_0 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Assets written to: resnet50_saved_model_TFTRT_FP32/assets\n",
      "Done Converting to TF-TRT FP32\n"
     ]
    }
   ],
   "source": [
    "print('Converting to TF-TRT FP32...')\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir='resnet50_saved_model',\n",
    "                                   precision_mode=trt.TrtPrecisionMode.FP32,\n",
    "                                    max_workspace_size_bytes=8000000000)\n",
    "converter.convert()\n",
    "converter.save(output_saved_model_dir='resnet50_saved_model_TFTRT_FP32')\n",
    "print('Done Converting to TF-TRT FP32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "colab_type": "code",
    "id": "dlue_3npkVQC",
    "outputId": "4dd6a366-fe9a-43c8-aad0-dd357bba41bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['input_1'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 224, 224, 3)\n",
      "        name: serving_default_input_1:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['predictions'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1000)\n",
      "        name: PartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "Concrete Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_1: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_1: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_1: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_1: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_1: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --all --dir resnet50_saved_model_TFTRT_FP32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, let's write a couple of utility functions to use the model for prediction and benchmarking purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rf97K_rxvwRm"
   },
   "outputs": [],
   "source": [
    "def predict_tftrt(input_saved_model):\n",
    "    \"\"\"Runs prediction on a single image and shows the result.\n",
    "    input_saved_model (string): Name of the input model stored in the current dir\n",
    "    \"\"\"\n",
    "    img_path = './data/img0.JPG'  # Siberian_husky\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    x = tf.constant(x)\n",
    "    \n",
    "    saved_model_loaded = tf.saved_model.load(input_saved_model, tags=[tag_constants.SERVING])\n",
    "    signature_keys = list(saved_model_loaded.signatures.keys())\n",
    "    print(signature_keys)\n",
    "\n",
    "    infer = saved_model_loaded.signatures['serving_default']\n",
    "    print(infer.structured_outputs)\n",
    "\n",
    "    labeling = infer(x)\n",
    "    preds = labeling['predictions'].numpy()\n",
    "    print('{} - Predicted: {}'.format(img_path, decode_predictions(preds, top=3)[0]))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.imshow(img);\n",
    "    plt.axis('off');\n",
    "    plt.title(decode_predictions(preds, top=3)[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z9b5j6jMvwRt"
   },
   "outputs": [],
   "source": [
    "def benchmark_tftrt(input_saved_model,batched_input, batch_size):\n",
    "    saved_model_loaded = tf.saved_model.load(input_saved_model, tags=[tag_constants.SERVING])\n",
    "    infer = saved_model_loaded.signatures['serving_default']\n",
    "\n",
    "    N_warmup_run = 50\n",
    "    N_run = 1000\n",
    "    elapsed_time = []\n",
    "\n",
    "    for i in range(N_warmup_run):\n",
    "      labeling = infer(batched_input)\n",
    "\n",
    "    for i in range(N_run):\n",
    "      start_time = time.time()\n",
    "      labeling = infer(batched_input)\n",
    "      end_time = time.time()\n",
    "      elapsed_time = np.append(elapsed_time, end_time - start_time)\n",
    "      if i % 50 == 0:\n",
    "        print('Step {}: {:4.1f}ms'.format(i, (elapsed_time[-50:].mean()) * 1000))\n",
    "\n",
    "    print('Throughput: {:.0f} images/s'.format(N_run * batch_size / elapsed_time.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "pRK0pRE-snvb",
    "outputId": "1f7ab6c1-dbfa-4e3e-a21d-df9975c70455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serving_default']\n",
      "{'predictions': TensorSpec(shape=(None, 1000), dtype=tf.float32, name='predictions')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 21:58:32.954219: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:446] TRTEngineOp not using explicit QDQ\n",
      "2022-04-06 21:58:32.959905: I tensorflow/compiler/tf2tensorrt/common/utils.cc:100] Linked TensorRT version: 8.2.3\n",
      "2022-04-06 21:58:32.960022: I tensorflow/compiler/tf2tensorrt/common/utils.cc:102] Loaded TensorRT version: 8.2.3\n",
      "2022-04-06 21:58:34.118186: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:1372] [TF-TRT] Sparse compute capability is enabled.\n",
      "2022-04-06 21:58:34.119278: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:36] TF-TRT Warning: DefaultLogger It is suggested to disable layer timing cache while using AlgorithmSelector. Please refer to the developer guide in https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#builder-layer-timing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/img0.JPG - Predicted: [('n02110185', 'Siberian_husky', 0.5574509), ('n02109961', 'Eskimo_dog', 0.416017), ('n02110063', 'malamute', 0.02126342)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHEAAACBCAYAAAD37FXJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7yUlEQVR4nO29Z6xtSXaY962qHU68+b7cL3Tunp4kRtEjiR6TMklRlAyDhinSMGHZEC3/IGzCghMEWhYgGzIg2QYkAg6QCEkWbVkSBQk0s0iRHHJozgwndM90mI4v3hxO3Luq/KOq9t7n3Pjea4Jiqwu47+2zQ4W1asVatUqcc3xY/mAX9fvdgQ/L45cPkfgBKB8i8QNQPkTiB6B8iMQPQPkQiR+A8r4iUUR+UER+rvHbicjT72P9hyLy5PtV3zH1/7iI/J3fg3rfEpHveL/rjeWRkCginxKR3xCRPRHZFpFfF5Fvcs79XefcH3+/OxmLc67nnPv671X9f1BL8rAfiMgC8E+B/xj4v4AM+CPA5P3t2kybiXOu/L2q/w96eRRKfBbAOfd/OueMc27knPs559wXReSHReTX5t7/HhH5uohsishfFZGqTRH5D0TkFRHZEZGfFZEbjWdORP4TEXkNeK1x7+lw/SdE5PMisi8i74rIjze+vRne/fdF5J3Q9n99zvFlIvKTInIgIl8RkW+c69PTjd9/S0T+crheE5F/KiK7gTv9i+ZYG9+8ICJvisgPiMiXReRPNp6loa+fPGdffXHOPdQfsABsAX8b+G5gufHsh4Ffa/x2wC8DK8B14FXgPwzP/hTwOvACniP8N8BvzH378+HbduPe0+H624GP4ifix4D7wJ8Oz26Gd/9XoA18HM8pXjhjbD8OjIHvATTwV4DfnOvT043ffwv4y+H6rwA/AaTh748AEp69BXwH8IeAd4DvDff/AvBTjfr+FPClh8bJw34QGnshDOA9oAT+CXDxBCR+V+P3nwd+MVz/DPBnG88UMARuNL799Fy7M0Cce/bXgb82h8RrjeefBf7dcyDxFxq/XwRG50TiXwJ++rj+BST+twFe3964fwU4ABbC738A/IWHxccjKTbOuVeccz/snLsGvBQ689dPeP3dxvXb4V2AG8D/FNjPLrANCHD1hG9nioh8i4j8sohsiMge8CPA2txr9xrXQ6B36sCO/6YlIufRHf4qnrP8XBAf/8Xc8x/Bc5p/Hm845+4Avw782yKyhOdsf/ccbc2UxzYxnHNfxc/Il0545YnG9XXgTrh+F/hzzrmlxl/bOfcbzepPafrv4TnAE865RTwrk0cZw0OUIdBp/L4UL5xzB865H3POPQl8H/Cfici/0Xj3R4DrIvLX5ur828APAd8PfMY5d/thO/XQSBSR50Xkx0TkWvj9BPADwG+e8Ml/LiLL4b0fBX4q3P8J4L8UkY+EehZF5Psfoit9YNs5NxaRbwb+zMOO5RHKF4A/IyJaRL4L+GPxgYh8r4g8LSIC7AEGsI1vD4DvAv6oiPz3jfv/GC8rfxT4yUfp1KNQ4gHwLcBvicgAj7wvAz92wvs/DfwOHgD/DPjfAZxz/wj4H4C/LyL7oY7vfoh+/HngL4nIAfAX8ebO73X5UeBPArvAD+IREMszwC8Ah8BngL/hnPvl5sfOuV3gO4HvFpH/LtwbAf8PcAv4h4/Sqag9fVh+H4uI/EXgWefcDz3K9w9t7H9Y3t8iIivAnwX+vUet4185B7iI/Ezwwc7//Ve/D335j/AK3s845371kev5kJ3+wS//ylHiB7F8iMQPQDlVsfnJX/qsK4oCABFBRFBK4ZzDGFO9F5+JCM45rLUopap7qPCdcRSlIW93SdMUUY5W3qXT6ZKmGVmWo7VGa9CJIOIQ8fUrEZw1QOwHpAq0OLSSqh9VcQ5xBPO/vu/EexCcA4ML7gSZfSeIGF+f9Y8cOBfGB1jj67DW+bEqMMZRTCZMJ1Occ2R5jljHZDRiOJ1QWA+zEz0Srn5WwS6UTz9/9cTPTkVikiRzAzq+gXgdkTiDQMDiESuiApIUSZqSJEKr1SLLMpIkQSk8crSgFYgAAYEIWARBUAKimpPnmM6LVAir/D4SgOQq7FI9di7Uc7bTJ77mginvnEOcgHVgHKYoKIsScX6STMsCa+1pVc51fRa+Sp3OME9F4nxl8/eP61h8PyIyviMiAQUeyWmSkGYJWZ6RpilJohEFuoHAiFSRGTygABFLlAYOqUAf0TOjrp2Fl/Cyc1TUP6Pvzet+1cRx4TuHNQ5blJiyxJaeTKejMRZH4SzuVA9iVa2H0RwCHxuJ5y0iggvQkkbDIs7PSOtAHEonniKVIlMJqShSrdBKPBIDZ5OqfY8SVQ0yFKeIY5sjrPP3OfDV2G8aiKnHPluxHycziI3ipSwKyqlnpSKCdY7SWmycEY2qtNaBiQvWWax1jTHXbZ0HB2ca+035F2ViZJuzgyVQngvvJTVAnKdIz2o1Wid+holCa4VSglIN+nFSsSvRgUKYnaVB1FZ9rGAUn582qEDa8f36C3/TudgVNwfEo+QZl4OMsRSmpLCe6pyD0hpM5LkNbiEiaKVRAUnGGHCG+XIWBcZyKhKNMZRlOcM2m7Mjyj+ttb/nGvfS1LOZ0uFKE94HpYQk0R5xWtNc/I5KEXjMicJTr5IGsOtinZ+9LpKieOpycgYSG6R7hMm5+Z9u5r5z/o4NdTQnlYjgEqGcOKyxWByu0ZGZPgkV3Ly+MEsYNSd7TEq01nqgNhWEekET8IiOGquXJ0KatshbHcrSYKwN8suBsohWnqKcBCpUFXBMRAq2VliiYuMbr1isB6S/LyjPbhsYOIvDOhzHqxpHv4rDtRaMqeW7a1IjfvJonWATi3E2fDdXX8VVIEm1h6FVR7T9hymnIrEoiiADXMXnVaCcpsISi2eZgiiNUpokEUyZUJQlEQGR+kQpHIJxFnHKa3oeE5X2qRReVnJU6JsgZq11HsmqYU1UuJwlqyPAOUEDaiqp1jlsYK8mmBURFpF6jDEVErRSWK0xxuDMURYZe5AmKVmaYZ2lLMtTZeFZXrUzTQzwyDHO+tmj/T1jTDWYmi34XkbWorVG6QSdZBhjSJQjTTPSPEenGaJTj0wBCXIx2oBeTjpUUGqa0sG6AEwLzgq2MvOEpNZ8joynSZ1yFINzb87dqajRT96oG0RxEmERRUK810S4BLVXiSJNE5RWYEErjdb2iJ7RZLGnlVORmKZpNSRnLQ4/05RSlGWJMQYRadiTDlEKUfUsSnQCKShl0Imm0+7SynOSJCVJE0QJOlEkKth/Alo5j0Dx2mpTVXF4u9PhtT8TYkzEClaBiRMJQUkNgHkqPE3lr3ViVylUANZZTDAfXKLRiUY3ZLwxtlLgvJyjkr+zslOhtArXoLSvw8URBjZcUfsZ5smZSIyCN85Ab5SrmdkSZSJ4T41WikQH5SRNwFkk0egkJc9zkiQhSb1WmuqAQBXtP6kQFyVePYgw0wMl2jDTLaCcBC9MNE9mEXJWac74aAPGbyuadX4ym6JAjAYyVJrMwCFqmzqMf95kaXq+IhK9mJnVRKPc1VqjEn1q389E4rybLUmSI2Te7KDWqf8OP+MQi0v84JLMP8uyFKWDphqpTVw9sLpmLNHdhaeAQF3WgLPBxScqvOcQ1ZBXwaujvdo8009OYVOVw2DeALUOZ4x3q+FFgNb1hJ6HhdKqakdr3YCR9hM5iQqhaphm8Z7vSaTa08qpSMyylDj7oxaplcbhKmQ2JY21Fp0k6Oh283eDjPPUqZVCa2/YK5HKjIjgqwyJSrGIPspZuFvjDWRPmRFJvjve2+NfVl7soKABnErRnilxYkbcOQTCBLLWYY2p/5yjnBaepQYEzU9sEUHCuNMsrWCilPIcTVxlaoQhVP0LnggPhsfx2ORZVglnayJQlOf3CWjdtPG8DFFKV7PIuhIwXrYpzzZ1YJsqWNUeAd7sIMoz5cfgfa5eeSmNnQGyC16OgFLPRkUgmCdaK5wWJMhWhQQb/6iTwlcatd0mMOPkdJRlSVmWFEWBc96LW04LdJjoIlTyMEmSoOx5G9dTno4+hqBl1/LeKW8uNZEYdP9qvI+MxFarhTEGayxG7Kympby7iNBYpdigPIJCsJeI8ygL5kXTLgTvqHBh1SNMfMTG0QUqNF5hiUiLwGoGkzk365AwJjgdkkDxEqmjBo5/1/9FajOl9Vp2LYZxzlKWhmIyxZRF9ZFxrjIPtFYoDSKe2xAmjlIS2q+YNJFdSKO/SqiokYDo47jFQyOx1+tRFAXTaYEpDcaayisjzhvsHoKETgUkKo0TFxQiT2VaeV+hl2EeWZXNRTAnlHgZoKQCrLN+icdY374xBmejHlc7BeIykZ/NYbVD6QDYerVDCOaMjte1G9EaiykMRfiLCAbCZC5QCFmeB83a27tJknqRoT0yEh1VssABACeNMflZN6N1usoej3ARIqM5IpsfBomtVk6aetYwHo8R44FqrUWcoJCZmQOzXncrYCTYVSLx4+qe83ykdiQohVLR3VbbXB7Anp1ZY6i9gLZCUIXEIFcrt3ZlnwUCUookEdJUV88R/421UJaGaTGlLMsA6DC+YEq1WhlZnpFowTnNdFoyHE5xzjAejxAUWWrJWy3arZROnqP8dPOICQzVulr+Rzbqn9NApJtB5iMhUWuCjMuCdirYwMKss0gwwav/w0DTNEGU12iLovSKkSSerTiDWL/Wh7UYQ6X5Vn5YXbuzonljjUegcwEMATG1nKxnanCCYZ2ZUzY0orTvsYo0YrEuekw8tbRaGVq3/DitxRjP7rMsJUk1OhEO9scMB4OwAjHlwcYDNh5sUxrH62++RbfVIUlSnn3mKb7pG56n08q8HHeWvb0RX/nSm3zrt72ITnTV/+gZs9GREf4v3clUeCYSI/tRyi/imkgFEoVzsHn8Ci1KFHmek+cZojwFRXYMCtWwj6x1lK5eua8UKGsB48EbKdE6XHAS6ySp1PrIFYyxmKjGNvqugm82tumvxSNC62ryWavrb5Sq3qvYX+CBOvGy7nA45v7GFgu9Nv1U2N+f0M0S1p99krfefIdbVy7x/NM3ePnl1/gHf///5vbtP8xLH/0Y29u7bN67R7fd4oknrtTjiEZoPQvD/547HHXePQQSVWWreI3LpDnGjFDaq8hpogOAVAW5NE3IEkEkweJQiUZpjQmuKK08wKyxyLTEuTgxVBD+fvpFu1AColXmKTxqeb4OhykNpTGUIfRBBTvM/0kwhbwcjN/VykY9eWrkR80x8jhwokiDtvzWe5u8/e4dnrx+meV2QjGZkGm4vL7G/mBAKo5bF9ZIrOXa5XUevPM2v/Kzu3zlS1/mcDjluz/9bXz8Y8+ysNAmleB9UkHSUIulqP+cQ685Yz0x+vLCinuaakRaiAhpokmCEV8bN95hnYjf3GcRjBZ0ngWWWnv/rY7eiJKytEEueOP2OGdwoqlmbvTheHaTYKytlnwkIDLGvYhSKHy8TaR6ooID3g6k0v2ryavCS8rZ0J7i7Xt7/Mqv/w7P3LrCcq+NxjCxljzLGQ0H9Nst3nrtNQYHA775j3wrn//i71JMh7z5+gPGh/t8/w/9IJPhPge7W1y+8BQ6MnTnFRvwcT9KBTkYnPrqjMiOc0WAKxG83zuwMsSHUWg/a1VDHVcBgcqF1Qi81oaLtqHXTMsAsUylJEm4GRQMVFRKaiTqYFdFRBEmiUdm9HJI5ShX4VqqjsU6w8R0VG24ZqXUdhwEFmuF/UnJ519+naKc8vSNy2RaKKYl4/EYi5+8d2+/x5c+/3le+PgnuHfvHl97+RWGh7u02x06/Q4bD+4y2tvjj37qD9PKMyq6iwqUgBUPOHEeu0odXUd9KCRaHBrlkSKgtcNpDxolro6FabKj0DHt+4YSr6VWHZagfAdkGwe2cphLhYAIcAmA1IGSK8hCYDcRG7XjwX8TWXH8xtWadLDLIruywfHgGuCKa4Qax9jC//flN/jq117lmz7xAp08BecoS4uxhl5ngfHkgHt37/Da66/jWl2+8PLL7B4eMBmNMLZE58/y5Zdf41Pf8kkWFxdQYeXaCuggF8X6sVk8a3WAEs9uH9nE8GzZs6JouEZ0xZkeKSx6aSKMxVGFDCrABSoTKscMqMBKZjpY/6oCJ6Q22KmbiRVXzmnwrD9+Gz0k8Q7N324OYdVEDDaes5ROsTcuePnVd3jl9Te5enmdKxdXScIqzmQ6Ic9z0lxx+/4On/n8F7n58W+Cdgd7OKC7KFy5+TSDwQCVdeksLpN2l8jb7bpvlX3tS7XM5uqdwCKP4QCPs1EhaCo5H+5VnKlimyhvgEdQxJ5VSAmAUs1uN5Bfg7uaPhXw65aZnZTVdaTE6DmKjDRSradYS1zo9bPfRU4RxULga8MSvvbWfb74lVd59903uXrlIs8/c5OlbjdQYYlSmqyV82Brl1/9zJcw0iNrGw4HB6xfuMjNp66wu7XN66+8zpWbtxiOSl5/8wGjSUnWTmcG0vTMuDmNxrs8H5ESNcoDXhw2OqxdQymIlBdZnavBJ42JXcmlhlP32C6FvruK/c5iy4VwjMbrRNuubpDjaxfBhZVI23iuAhnH9cnDQcnG9gFfef1dXvnqa1gzwUzHLC90WVnsosQxHI8QpxiXjrffus1nf+eLHE7gcDBhsLuHtSX5Nc03fOxFcI5Ut3jmxef5nc+9gkF5n7BqDCVMJiPBhxp7FB0eZ/jezlBsguIiAaQuAhev/gd4VcsvrnHdEF/S0P6asWXHNFch5qRuu8b3trrX6NfMvblvnffqpoFlWRwlwriw3L2zw2d+6wt89ndeJmtnqMRxuL9NMR7x5FM36HRa2HKK0Yr94QBbOh/ZZko+8dKLvPPePXa3HrB606cc+PiLz/PMtavsD4e89JEXuPXUE7z2ytt8y8eeZbGVeBkss/EF1f+utp2VUo/nsYnAEiTM2JoFCjEkpnIezVBg9bqrNUZpVnoMmCPTOI1Kqx6Jq9r1itzsV6rxna367NFeWMfO7oiDwZh797f52Z/7VX7rs78NwJVrV0mzLru7+6TaMjjYRskT9NoZtjQM3YiDwyFOwdriEtcurNJptfnE80/xqW96iSTP2dkfsrbco5MLO7sluJKVfotPf+ob+eizV0m0YJ2n/HklzXP92lH/2OEZQkOhCEByUWlpaI6+vZrVhj5VIPbIicCnulO/GalrRg2ZKU5q9hKfKWwI1a9tRxVkn4hCsJQheOtgUPDG6+9x7/4+dzY3uXPnLm+++jW++vLL6FbG8voqT7/wIp1en72dLcQ5djY26Pda7GzeZzga0MkzirJg73CA0ornb16nlyVoUXSSjKXeOuOy5Cf+l/+NdrvPj/7oDyNO0+10mUyEq5dXaLc1OJnl/nhulwClCrALSHZmVoQ8NBIjMGVes6uAXOnsNWs9ZvbMi+VZJnKsllKvrTkb6g3GQKMfymqc9QpKYfx+h6L0vtXBsGA6KnnjjTf5xZ//57x1+y66m6OznOHwkL2NezzY2GD9wiWSNOXj3/CHSFttnCk43Nlif3cHLZadrQ2yTLG5uYE1hvF4jLGQt9p+pSPLgkz2qzqp1vxbf/rf5Bd+8V9gTIkSWFla5Hc/9zKf/vaPeoW6qbTRYJ0IWrwMFImrRI9JiTWaZtEQmz9vfOR8N44L7Tjxq+CYts5TVFE49g4GDAcTvvb6Xd69c592b4Evv/IKk8mUwcGQ3e1tbDllc/M9hvs73Hn3VRDhqWdeoL2wyhM3n+Rw+x7Xb1zhcDDiwuoqt568zr179/nqyy9z5+23GB7ssbi8xHQ8JE0V9+7epjSG/f19lM7odpf4/Je/xrd+8kV6rYxEFE4EjeYbPvkRXnzxOVp5SrfTprDCzctrLHayeurODTtGSSgn6Gj/zkD85HKOMP6AQgkmwnzjxwH/mDb9NHANVTrccX71fv9wxObWNoJjPJqAKMZTgxJFWRreevs9trb2eeute9y+e5fXv/4m0+mA1dVVWt0+Ok9ZWlqitAVJVxgPClYvrFMWQ6488RQHuxu8/bUvknf6HO49QLKUcmdKr9fmypWLKLEMB/uUkzFiSqbDQyatjDzP2Lx/n63NbRZX1njv3fcQSbh2M+PuvYI799a4fvUC7ST1bkR8SEY7z9BakaXQURolDuU0VmzDKjyKqIo+XZzsUm1XOKmcO/FClEW6ubp/rH1H5f6ytp5xlmhh+LVIA+zvHvLrn/kC/+z//RU2dw7ZOTjkYLxLouDpZ57mxpO3yLMM5SxvvPZ1Dg8P2NvfZWFxiW/99DfTX1jAlIa7d+6ycecOo0NH6Qwq1YhSHA6GrF55gvFozM3nXuTu7XcYHu7S7ffp9Hts3r1Lt9fj+q0bHOztcf/OHcbDEeApyoynGK1xhWHz/iY6y9nf3mE0mtBbXCFfX2FrZ59Oq8XFtSUy5Vdy/II0XoO3wWWInvVcEbcgzKLT4Sr5LwF+Pl7oEe1EOYYlz6yQH2GF/oPKlgzfV+8FI/v+1oBf+43f5qd+6p9w5/bb7O1uMJlM6C6u8tTzL3Lr+Wd46aPPkSawurRCMZnQXsiZTEsODwdYa1heXaHX67K1uUurlTI53Ge0vwuJYKZT0JqF1TXyXo/FtTW0Fj558xqHe7sU4yEP3nuXPMu5/tRTZHnKwcEOD26/x8HOHq12m+ULawwHQ6aTCaISXn/lK/QX+yAwGQ0Z7O3j1taYmpJpWbC5vcPFC+vBVVePOW64ddF9NceJjmoM4duoQR4L54dB4kxj5yhNm5Cg5le8wVPvl9+4y8/86u+yuXGf9Vs3WXriGtsbmygltPstrl27RK/fZeP+Xfq9LqkS/NJUwcb9exgDSyuLdFspk+Eh7771dR7cf8CkGJKmKfs7O+zc36C/skqa5hgnXL91g247BVOy8+A+r/7uFxge7rN++SrXb90ELHt7O+xvbbC7tcMTzzzH+s2rDA8O2H6wQTkpGR1s886rr4NOGBzssb++S1EUZFlGmmWMRkP2Dwa08pxuKw8uMx/MNZlMabdaQWuu7UCF+LAMV1NkBFe0r+P7j4xEFfQoJyFCrYFLVzV2OoKdRMp03N865Gd+6XO0FjpcurrGwXCfYlKycnEdEbhx4wrXrqyhgGI6RRRsbm6SZRlb9zfZur/BdDpl72AbZwyra6sorRgcHpLkKePBkNHeDtaMcc4xGg5YWF2lnIzJ+m0Oh0NMWXCwvx+iwy0L/R69bgdXGqbTCZPxgCTLuPLEdabjIeV0yvbmNlm7x4P79+gtL9PqtvwCMcZHfZeG/sIig/EUpRKyNK5tQmFgbzjiQprQUkljgVdCGGXtUIzkosQvRQXX8OMh8Wip+eupqJtxnQhOLAbHV9/epbXY5nB/j63tuwz391i5cIHFhR6XL66zuNQhVYo8T9je3mZra5vB4JDd3V12Nrcpi4LtzS0W3DJFWeBwXLp0kcP9A1wx4d03XmNwsIeVlO7iMmuXL+Mw9LttTFHgTEkry+kvLDA83GU6HjEdj8hXlshbGVmeMh2OmI7GGAcXL18CZ5lMX8bsGIbDIct5zvWnbvr11UTY299hsdcmzTI6nQ5KaSZFvXvr9r0t3njnXT7+wpPcuLRKjPyL8TOVyAkIi56xyv4+Rzk1KvU4Kjtyp3IaHy1N0/3egwG/+dnPURQjWm3N4f4eu1tbrK6ucOPGVZ64tk4rT5hOJ2xsbLC3t0u326727okzjIdDRocHDPb22XjwgIODfbIsodfrsrO1xea9O5iyZP3KEyyvXcAi9PpdwEcnbG9ssL25iU4TimmBM4bh4JDB8JClpUWuXruGso793V3K0tLtd7l6/Ro3bt1kaXGJlbWLdHp91i5e4OLFVVp5gnUG0ZrC+t1NxvpQkdF4yvbeIX/zb/4f/M//49/gH/3jX8QYe8RZVVHiMTCs9IozypkyUTczIEdbg1mBq463KqqPSuP46Z/9DYZmih5OGI2GlOOS1fU1tBgybXG2wFrH5tYOu7s7pJlmPJ3Q63UwpmTQyinKTZJUk2YZBwcHbNy7z+WrVz3bvfMOe5sPuPzUR7h66yk6C4skidDp5JTllJ2tPe7fvctkOMIZQ97qsHrpEipJmIxG9HttLl65jGjD/s4DbGnJ0pxWnrJ6YZWtBw+YOuHqtetcvnyJxX6XRGmsMQzHIxYWFtFak6aKXjtnb98Hli0urtDutPnoi0+TKFU5u70DzOCs8g75AFaHX1WxzrvrkXpb+yMiMXpqGvbdESM1alOzbrMKheLY2h3w6tffYWV9iY17DxgMD7h87QLf8s3fSFGUfP3NNxiNFnCu3p2cZZr9vT0fAp8mYSdWQZanWDNlsDflzmTCaDDkwZ3bbNy7TW/5Aheu3+Tak7fo9btMRoesrC6jlLC/u8NwOGI8HpG2WnSUotPrMRoO6fc6pGnKpWtX6Cwucrizy+233+bWrausrS+RZBmdxT5Tp1BJyurqGgu9Ngrh/oNNNjc3WV9dJ8syslTRSYTuSp/heMJ/+ud+AGv/Ha5cXAMN1gY/tAg28MwqFhWq5b/oD54JZH4UJNaYmPmvQto8Vpv+XP++wxr4+V/+bVSumEwGtFstFhY6fN/3fAdri13ubGzz1VcLNra2yJKUyaRgMpnQbvucNvv7+/T7fbq9LlppjCkYjYaMDgfYYsIbXxqwt71D3l7k0pPPsbx6gZWlJZSyrCxdottrs7W1SVGUZHlGu9NmeLhHmmekrZzptAhrgwqw5J0+o+GUw91dBoMR/YUO3V6X1YvrtLp9Or0u3V6PdjsnTRIQjdZpFW6ZJAmiNcpCv53Ta2cA2LBiP7cCBdGmdnO4iuud58iccj4kNuxFadxSZ8wQgOG44Atf/ipZv8NguA/W8n1/4vu4tr5MOS3IEsWTN2+yu79PWRQUpaXVaoOFg91DnwPGOXSaMTw4IO/3WFxcZtIZsrtxn/F4zLWnn2HlwlWe/ehLaK24cHGJXr9LUUyZTqdYY8nzjPXLl3DG+DATZ2nnLfZ2dlhdXyYlI8tzbty6iZtaksQxODhgr5MzGIxYWVmjv1AymRjKqWXtyhq2KOm3euR5zkK/j3OOllI+bwAecbWhFpwjAYtiIQm7uUT8UrohLFDHTBoxauH9CJTyBs4MzVd+h9NkIU743Oe+wu3bt7n+3A22d3f43u/6Tp584gqJWCbjCcPhkLyVc7lzieHggOXlRb7+xte5/+AeOMhabdrtLi6zlIVBT6a08ozFfh8n8MQzz7CwtAwoOp2MPM+xzrG7u8tkMsWUJVppkjSlt9DHGkOaKZy1JHkGStjZ2UEpRa/Xw4b7WbvNZDzGGsNoNKLVanHr1g1M6fx+DCe0WjnFtKDb6aDER/kljWiuCKHK0pa5GNPwoHKeIIhzaPHGXdyz+djriXOoJIY51KhyR9EZeL6zjr/3d/4haSaUpeHZ51/ikx99ibby2tvhcIAD7t29y+LSMmsrS6Qa8uQWr3zNsb17gE40Kknp9DtcunkTW0xQ4lhY6nP12mUmRYFOU0ajCVmWoDVkacrOzpD9/X2MMRwe7qGVwljjg7/SlMl4RNbK6fW6tFoter0e29vbJHlGa6HP0to6SaYZDA5RSrGysszF1SWWFpeZTIxHdpIjCGVZorWim3Vnrasz4DnjOQ3cLrJbHW44kTMz8J0biTEEMfaySrlFlS9hroOWO/c3ubuzxfrNa+StNi88+xT9VuKTDVhHnrVo5VOSNGV3Z4deJ6O32GdtaYnr1y7T7nSYTEp2dvZptTp89BOfoJVqhoMBh6Mh1loWel0GwwGJsty/8x6ihTRpMRwWWFuSJIrB4SBs6kxJspSJKej2eqRpysrKMq1OB0FY7Pe5ev06KxcuceOpp9DaoRPN6uoy1y6ts76yRLfTQ/qp35siQpIlWGtItI8s92EgZ9l4tUutstCcXws1Yd02UqAmarInl3MhMQY4yTl9eTHU7ZXX3uHClaukecbq6iI3r10gVY7RZMp4OvZxo9aSJglZ6lkhwGgwIEsUV69cZP9gTKvdoZiWZKniEx/9CJPxhHsbD7h77y7TyZjD/T3u3rlLmuSQCEtLK0wnhrIsaHXa9BcWSJMUpRVZntLtrlOMx/S6HRYW+3R7fcQaRqZgdW2VdrfH6toaRTHBWsO1K5e5fu0yC90uSiUICVp1PPLShERp2mkaQipPXuZx8yr+3GKGRPvjSBWP4TutGg/tzWufpxVTwq//5pfpLvYYjvbRqiRVFmsMk+mE8XTMcDzhcDBgMp2ysrxS7cUQBb1Om7zVpiws29t7ZFnGtSuXWVvuY8sunXZKniuGwxELC33ydpud7T1GwwGDg32std6pvtBjZWWNXq9HWRZ0e23SREiVIss0rVZOK8sZDw9JE82Fi2ssLa+xtLjAZDqimEy5uLpCN8/DhtEEnJDnCQcHI0RS2p2MVpZVmebO62uJ0XbN3/Gi2vkpZ8P83OxUxNVpuOK9Ezsn3Lm3xXt37nL15gr9fovLly7QzhNKU3p/qnJMyjGjyZjFhR5FMaaYws7ogCzx6UN8AxacZWtzg489d51uu4XSirydsLK6yHRa8mBzh4tXrrK9s8/td2+zv7/D9s4GnW6XNNWoxKcfW1u9QLuV4TD0Oi2yRJPnOWY6IaHDUIT+wiLLyyskSYK1LUxR0O/26LQ6VRRe3Fef597M6GU5La0rQ34ekc1FcM8+XSPux2uuznltNjo1xdZxumcx6POx02jQn7Dg23iz0r5eff09br/3DgeD24yGU55+9gaj0ZBOyN9irSVNNEsri3SmJTs725TllERgWpSMp1PSdpuFhUWmb92m22nT73t2Zqyh3e4GJ7QmSXPynT2KKSTZFnmny1qiMIWh027TyjPyLGGx16XbaZOmCb1u7pUHgWHYR5amKWmas9DroZSiKApIc7Isw+E34VhL0BwVrSwnTxNaWdrwfZ6vHCfnmh7Mynd6DsI+PyWe90U8En7pl36bS5fX2dm9w97mBm989VVeeuYWZVkyLaYhFM+FSOoxSaKZTsYkrZzJpGA8LeiGCbGwsOBjW5WnHOJ2NeV145XlFdI0YzickiaaTrvH7mRKu52xsrJKv9/n0oV1VhYW6LbaJKlUu6v8hllLq9WiKEo6nS6tvOU3sypTLd34dcG4C8zvtsI5uq3cb2doIOC88JylT5mr4PwQPzOM3+/vCOpuvMl89sH4vk8MNBoXbO3vUZQTDvf2yTRhC5qlmJboxKcKc85hyikKx3BwAM5RpAnDyYTxtMRYR1GWKC1cvniRhf4iSZohwZmotF+yESyL/QVu3dR0ul1efuUVsIbJeESeZvS7HVYW+iwv9kmVTyIU/ZFlWTLVSfCTOq/Bao0BUpcGePocBQ4fCZ8kmjTR5Doh09GYPw56+HXU5nPvpqnuNBP+RaLzUepSUeZZk+N87DR4ZmP6vJMEbUT1e3c26Sy0KclZXV9j694dNh48YDKe0LrQYlIW1QCM8et4ZUhoMC0KDgZDsiyn3e5SFAesrq6wurxIt9Mmb+TWsYRNM0ogSVjo9byT2ZY899zT7O7skaYp62srLC8t0I5pSERwzkfOmbBrNs9ytFKUjTxtWZYxLfySFxJ3ZwlpominCUkI0zxCRA14VHgjysbj+aiLmiOEXcMBmbgjMbXz5XzaqfNbrgTOCNrxjvKJU+gU8laG1stMp0MGgwGT8QRjvEfXGMN04lc03nvvNkVpSNKcaccynRZ0Ol1GozFlYeh32lxaX6XXadPKvSpfbTixDuMsRUjRYvOM609cZVqWdIIR3223ESxpSN8JIZGCdYzHY/YO9um2O6RpxnhyUCUmTNO0TvbgHIkIWZL4oKgwkx9GDta7go+D8ewDi99uYIP/+bEVm5itSZ2i60bPjQXub2xX2SSmgwlpktLudYJRTZ0TLk1I04xut8vO3j7jyZSiNIwGI3r9Hru7u/R7fRZ7HRZ6Xdp5RhazNIUlMqc8E9fK+UR3oihMSVJMsf0e3U7XpygLgcZaab/MUzpMWTIaj5hOgoy2PidAUUyx1lGUBSKKdrtNohOyJCVPMxJVBysH9DRcbMfTZEMgnVDCpHC22ilmqf1hp5WHcLs1dx3NlmjTaKC0jt2DfZaXl9jZuY9ONcODA7qLC+wdHMDlKz4ditLeKSzi8wGUhuG4IE1znPh8cu12zvryApcvXWCh2/bRZFDtqoWoNfv9knkCaSJMS791POn3qXLuWA/K5uaUaVngHFxYW6PXaWFMSaflNc7SGPYODxDRdPI27TSjm/v40kpZOIKCWqbFUptKjffCrVkuGRPPq3oZKsD76KG2s+XsQKnwT8PqOfWLw1HBYDDyQExSrBWWL6xxeHDAzs4OpbN+Y6mFVt5lWhqcwHgyIU1zv+LQatPKMlb6fa5dushCr0MnSytOcJrHqJVoEu3zik+nhokpff6dUKqUKmGzSp5ntNudQImKLMsquZnlGYeHA1pZQitNSJRCuahsHN3A01xmminzonBOWFaBUnPvCCHD1fuzinFKaVj+FtgbThiNRuzsbJGmGaUR2v0ejgGbm5tMiwJjDQ6vGY7GY4y1dPs9hITxeMqVS1e4tL7E5Yvr9Not2llKpmoQzTiO4/8NFTAR0GlCpjXaKKal8VmQg8JSliWJ1iiVI+IRVxqDbSRvwEGv0yVLUrIkIUv0jI+4uRhRg6Jx41yC8uh4qs+rFY6Td4jF8r6c2ibElSrH3t6IwozotDskiZdFd2/vsbi8yNr6BdIkw5kpxXTKaOKXoqwFrRJKY7m4vsYTly+yttz3K+6ZB2J0Gp/PFgtbzpXQlYRUaUzqU3uVxmIS7zBw1pEnuc89qhzO+IloTOkXeIUgA/URQJ0kXM5cuWisGgh+a4IVNTMpqijDsJfxffGdnrcYhGlZkOcJm9MJ1pQ4V9Jd6NNfWKDX72Osd0xPpmN2drbZ3d31ab+M4dYTT3Dl4iUWul363S7tLKedZlWuNKh3E1WEdwybqjM1eXu2pQUIaZ3D/So/XNgMdDgeY7T1ieSsT2ttnCPRSciiGDcNSYMaz1Y7ZinJhS3u0TeqZja8hjeqCPr4+7FibJqNn6aXRugNp5bxZIrSitFwRL/fYTia0ul2GQwGFEXB4eEhuwc77B3uMxwe+g4r4eqVKzx54wb9Tpc0UV4OJUEblVldQgVHvJnt5JGe11v/giEtkLjgUZ5L9jDRKYX1eXVcyJZnnPVJJ9Txru35vK9V6ycCK3ATVxv3xtWIa27zjtxNizxeMqJGJDkVIueWMmJwq+DY2h2xub3BdFLgjKUwhrzTYTqe0m71ECyT8R4H+zuMpwWdVoeFXp/FxUVWlpZZ6vszoxJJyNKEvJUekS1VZJ0LKVFcMIGOA1wD6tL4N96RmqRItUZKjeAT87mQVVIJpA/ldJxtvsKKpUrChzicja7t4EgJMTgx6aE/jsF/q09R5OAh2ekpkx4D7OweUpYFBwd7rKyvUZopDovSmpXlFa5eukS3pcn2D1HaO5t7nQ4LCwt0ux3aqQ+OUkrRbgV7rAFoP+xaO20eanLEO9Lo4oxMOQKQACilvA2pYi5ujXIWrZPgcgtRMufYuRvbcTPHMEW7L5gPrl5YcEE9rQ4jw82kQTlL0J5/VxScsLXN8/xJUVBax2g0YDIdk7c7FKMpk8kYYx0v/msvcO3yJex0zIV1wVhDK2/T6bT9qrv2J7YoEVpZSt5I/zXX4LG3pDGZZt5zc7/n0BuJNbJbpVRwxcXDyZJj6jgePkf61WC3VsC4BhLxOXJm95Y5vxwVNh6ZoCWfdVbY6XbiTM8keBEaKU8a3TfWrxUmqd/aNTwcsruzTZIlPPv8Szz39NNoBSQp/f4CWiekaRoyVBFSZPpMhu1gq82DRs4BzGiIVD7N6Jc8pbgwppDJk+BS8KsWkeqPwOME5/T8JA8yzcZZ4nxqej2jqPmPVMy0GGFdnQp3ev/PsSuqcSUNPh+ncHhUlIasldBq5SBCMfF+0qsXL/DHPvVt9DttTDFB6YROmqNCoj5RPtG6Vo48y0J+0ONj6Wrx3HB4zZGrNJ/P/nfGQGOy+PBFSAI/k9TopIpkfkrXFTvi6QFh5SdOzhBPM1+lNC7EnY1AOCOOaj4DYeykO2ZESSJkWUK368+9GIwO0Frzx//17+TCUh9xMc2yruSeCnnBs0TRaeXerQUcZ946AavOpqpHLZ6VhqnTPP+x0d55rdTGB34+SGOyNeJsrNAI6Y8fUL0XI+/tGTGLp+d2Cx2o7CnnN6b4VY06p5sAWeqPFer3e3R6HfJWxkeee54rFy4iNij5AlmSVmwoU5pWonyooVJVQNb8eKpGwu1ZEVFvaoWG0jNfxRmsWIkP5i1EfABU0mClLlLlyeVYMAvE9cTadgjnjMREvyEbcdwELq4RlK28P7V4HHbq1+sEUbPmhgdQrbFFHr/Y64KdcvXKZbSCWzduIFisDY7uxB9HlAB5ltJO0nAiaRx0Mx31LIDqo2U5gogmfmY4h8y+fqzyETROFdYKIR4TGBPON+o4KqbnKwvfuEriVGk4aTwLrFuQav9mnamyzpkHPnVmkj6GiRET6TVV+Ln+VkULdHKN9Hrcun6NpYUe1y5f8oJcVBXWICK00pR2qhsO49OhcxbsHrdELbI+VWZuQkh9fXbiyhPaoDmGeloZ6k28zCM89uFx7MRot0iVNYFqY2TtcnLVwmiiIE81F1dWWFlaop2mFe9TSoOzJFqRZ+EgsTlKmWn7uHuuBkZU9po2QkPRO7GO04ooz9pEFD6PXM0ZXGCNTYZQ3W90sKkueNYfTIy6FaIHyQBlkH2R7eqoSIWxaqX8AdanTJ6ztdOGpudiaANxhkQYxsH7tbtUa1SSIM4fxapVgjGGNNW0s3QmZVetXZ6C0dgexyAmIvCcNuXJg5XqrKqytPiTWGtpZiUmHjxG7WpMopks+9IAX9X/sE8/8LkUwdg666SNEzXMUD+VHoMS6z7WnpOZo3pcnaoLCSe6iaCScGyOsTNaXx6yFUdZ+rClUtNpsLfjWM0jcDw/6/0kNA50OPzTt1XXOTtZGpQn8cCxRsbJY1hBky0n8QwscZU3x83cO185Iwd4g3XFkdLonGKG0H3yWlXtzzOFT9WVBMSnwbCnUee8CXPagm+VwdH/ON8I58YzW+EsoEXCwVzSPFF7lkXOGxr1+B0xi5edo76ZLrggiKLJ5MDZWeoFX0c8Q2M2F97Rco7Mw4C46oSV6ID2/L6h9zvxJofyS6fW+EORlfIHg6WJItGpX6WWavJ64FH/f5Zvcl5BbXoCG3A+sw4XP6aWV4agRes6ytthMViUk0qGz5cmkmPmi+azqJEawKEq2zCeBe1CMnnvmmt8FxF7UsOhnH4wdION4sJOnWBqNE+nqZS4IOO8fVUfWCIi/pjWBtKi2aCifnpOyprhDI175y3VxKyuXRXjGVdojLE4HR3eUnlWmt82eEJDyZsbQ9BQnPMTPh6BNaOEhQojAiMsq53DLm61f0RKNCEbfHPQggtJhhpSLSJHBOVCSqzAWhsjIp4LFfs0A/ym3JmRmbNgiwPzPtxjhFaT73NUGYrXlgicyB6j5hkd0DYcaq0orSNRat6bV9cZNMuas9Ttxq5FRDTjS6FeIK4Wil1svzG0x1NswkCrtS7fwRkfRPgn+hcFn0EerRDtj9ZxITHLzPkTccbNqTj+UWAmIhV1zxRpvneky7OVcXS3tGs8nK9BaY1utTDGMjUGQVDexvKm1NxCcE2DrmGkN9YJqRMsQJCJgeKMRNi6kGBB6uOFkOqk1mOpvFFON/YNRJ9t5bWJqnDUhWlm5SfEjFBPy5Be/nA4pN3qhD0Ms/Kw6l4Fm6BYS72BdQbRUcE5Boc1+3d1ffNUT0MEEMMY/ZRIlKaTtxiOxn6vSNir4ZxU6WCiehZD8Alml6kaiXzRy78YPyriZpSYSnFsJFmICI4KkHPNeo8vpyMxZvmT4L0R/JE4EQnxbAcCZfj1lvrksYBAZz0Sp8bS7y/4sPvAWpsHkMw41iW4/KLftpKdtXaqG5Ohpi9PowI+gUFQNE5yXkfFwy9Z+a8TpXCimJbTinNY53AqHF8UDx+ZqWeO/YdVfOckGOs1X63eFGlQplTII8Iv/P9YSHTWk2HMHC+4ythtstZa6Advg/WHVpqiZDwZ0dd9uu0ODmEynZDkLfxhmbMSacaMrgYUlAOoncSROwRWK0QFKfQmIF0qioi2F5UR3aw7Or2s9fGoVgQnitG0xCh/9KwuHWQK4woS5c+8qg2meYRSIwZwompvU0OU+EEGZIut2b4EAIdlG3msuNPGWTyRSmKFcVUCmDHCI4tQCjYO9jDlwAfoZhmTyYROoqEsUDpFUydk9bI00mRgV5VC4Nuz4VAs42K6zsgnZ1cywozzdO5ZhH9HBTbS0KJcY2zGQemgNJb94ZSNjR3uvfsOK8uLXFpfY3lpBRO2iatE02rnlXye5+LOOQxew68UNY/RGoc2jMk1+0ElVysd6HEo0R8/FwAr3lzQDUT5iRyT2PpmPbX6VY3t/Qnj0T6DUcrG/fvs7u3xsZde5NL6CqtLqc/GS6QsaZgbDYCE+m3k6wGhvv0605WzDTOhOe5gg0X2HqPMqGryxpB/JhTWMS2N3zyaJuSpgrJgZ2uHza0BGw8e8OSTN1hfWfBnIkYsxhIoLWrqhIlhq0QLUXlpsM04hjBrJZ6BFKs8XTlFTjOuXzlwLrIuv7DpqrgQf69O99gciwMKa3mwPWZSjplOfc4awbK+vMD6YptunvhzF2lYBaErTcMkyt9KXErQ/Wpiqlj5/JStpI+blYiRUiAqD2pGm4SwC0wEcTaMPRj/1jvIJUxAE5avmisesd8+vtXhRFHiiMfNN08qb2qrfiLWvNMfhundYp+8cDIqzzxmKGqJVf8q9hG2uoUbUSJVqr+Ga2ttxGbVWYVWVDjVrV4BmTEfZi5lxk9btS1zL+Lv2fkKmr/mzILqozkScsTzNeo9gdFT5TVlQeKm0lrczgFtvr8y8zuy+uhfq9NmNuJwqJUd6zt1TEN1Off+RC98I0twTbFCRHQ4NS7I5cAeVVIBX1dyS85kESeXoxRXSdGGjJ7tf2TTxzTqYvgXlZpWwTK0FLf2NS3a+dCNs/paRQaIQ+sQ+eYak6sS1SEJQzgfytkGRzmhnD9kMUCpSW1Rn6zZaBVr7Q+eDDPPU606V3yMNP89EdPe5mr0LigBTX7g7/u+n74pZQZI84pKvD6xgsDMj1B2qDnqDU6CqebZllIxdsZ/E5JvBAMf6tPKzz4Y+owo/9lZ3fSwN0MposSpFI6KDQcrMNhM1TgfgQqbR9HNPan+mtX7vxqdJ06Iyl7xf1WAVPOVmdcaz9zsRDq2euXdkPPO/rrfvtTBxFSKUTXu43telTOj3WZv1CHzFejOaoHjAP9+lfPVW59D2ADUOcuprx6D8KO9c9TKS61NC7MdiRQ7s0ZLtBBO7+OZxr7oGI/pg3pi8HBUF12UDcFAig5bK/GY44oWTu/JY5cmA5xFbjNq7aGnkzTsNaD2TxG03qOspZbBkcKOyWkqVI4TF9bnoty0tvIen8tjcwY7rV1Bzs4qNRXIKs0w/CZuW27KoRqIj1rkBFZ3rm99xx5qGh1tq54c9e3AkuYQGal9ngNVx+zG6sK7kdqkUhxr+EXF6rRyKhJ1UqlMvvKKJQQbK9pBcT+ySIVU93vKRh+tvP/dOanC2elifRoqf93UMRqfN2E7o1g5NxuPe0w5lZ0mOpzCXfkZAyUGbU+abCpuZq8scyr8HxXqZ5fjJsDxJ+IceevY+iKranYtkuhZyJ3ty6yZ4etsBnfGb6gVOqXi4XNoVWubEjRUP654TL1Ujngl4JQ83hHtCeLXvCrPxqx9FIc2Y7kdAUgtrGmykzOKyFmU82gydqavnIM6jyCwUYP4cBVv0jWNrfhteE38c3HB3AkwjdH1DUZWUWRdhZzZxzNNDF+5IMr6jjRm9KyCXWt/fnzyqHCOrT6GQ+D9KyfBr4ryPgXCgo8jVa6p4M29E12PIo3grLkeHLdw2ijnTuQeww7nG4je+Srbw1z7leET5Wpd5fmafkREusa/vr3oi5l9aZ4yz1uUktmNLnOEOHtiQVRaTh9MlJdxW59fvpJwJNLJ5QzfaehbMB2a+xIFwpFy0ZRQR6BReSvOyqZzanlYtM9+GUE3wz1cQ4LJ6Ug8Hsn+bkzzddZEiLuboutOXIya98fyoeL5F002SiAKd+Ym07ON/abHQDzi4uFf9f49D2BpYljm6iHYP2cw+HkKepwyj/6mZTCj6j9kc02j3dt5J7zYgMOMn19qmzBOguY7zlmig9M697h2YmMmN73xNARw1cm5EMZ5zhVJoP7xCOVkiLtjntae3hqNceJV3pajtvrxpcLC8SbCWROhUgpDVRGBxzcVtf44pU+v/FQkqjDgOsxOKuPTs1hh3qtdUV1YN7NCI+hWBZg9ChJPJ5njnp4XP4rjTxSAWht3jRZqqgpR3+dsqLkQbI/hkU0JXjd0Us8affyXzSD/sDx8eRyN48PyL0n5EIkfgPIhEj8A5UMkfgDKh0j8AJQPkfgBKP8/pHJ0gXdvBJsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_tftrt('resnet50_saved_model_TFTRT_FP32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 21:59:18.288240: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:446] TRTEngineOp not using explicit QDQ\n",
      "2022-04-06 21:59:18.942325: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:36] TF-TRT Warning: DefaultLogger It is suggested to disable layer timing cache while using AlgorithmSelector. Please refer to the developer guide in https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#builder-layer-timing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0:  2.0ms\n",
      "Step 50:  2.0ms\n",
      "Step 100:  1.9ms\n",
      "Step 150:  1.9ms\n",
      "Step 200:  1.9ms\n",
      "Step 250:  1.9ms\n",
      "Step 300:  1.9ms\n",
      "Step 350:  1.9ms\n",
      "Step 400:  1.9ms\n",
      "Step 450:  2.2ms\n",
      "Step 500:  1.9ms\n",
      "Step 550:  1.9ms\n",
      "Step 600:  1.9ms\n",
      "Step 650:  1.9ms\n",
      "Step 700:  1.9ms\n",
      "Step 750:  1.9ms\n",
      "Step 800:  1.9ms\n",
      "Step 850:  1.9ms\n",
      "Step 900:  1.9ms\n",
      "Step 950:  1.9ms\n",
      "Throughput: 4135 images/s\n"
     ]
    }
   ],
   "source": [
    "benchmark_tftrt('resnet50_saved_model_TFTRT_FP32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to TF-TRT FP32...\n",
      "INFO:tensorflow:Linked TensorRT version: (8, 2, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (8, 2, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 22:24:05.584034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 22:24:05.584220: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-04-06 22:24:05.584305: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-04-06 22:24:05.584624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 22:24:05.584793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 22:24:05.584946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 22:24:05.585141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 22:24:05.585301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 22:24:05.585417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45269 MB memory:  -> device: 0, name: NVIDIA Graphics Device, pci bus id: 0000:01:00.0, compute capability: 8.0\n",
      "2022-04-06 22:24:05.638277: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1191] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 1202 nodes (878), 1857 edges (1533), time = 28.146ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.009ms.\n",
      "\n",
      "2022-04-06 22:24:07.012340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 22:24:07.012546: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-04-06 22:24:07.012603: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-04-06 22:24:07.013008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 22:24:07.013199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 22:24:07.013357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 22:24:07.013556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 22:24:07.013716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-06 22:24:07.013834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45269 MB memory:  -> device: 0, name: NVIDIA Graphics Device, pci bus id: 0000:01:00.0, compute capability: 8.0\n",
      "2022-04-06 22:24:07.267360: W tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:192] Calibration with FP32 or FP16 is not implemented. Falling back to use_calibration = False.Note that the default value of use_calibration is True.\n",
      "2022-04-06 22:24:07.267442: I tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:211] [TF-TRT] not using explicit QDQ mode\n",
      "2022-04-06 22:24:07.471742: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:954] \n",
      "\n",
      "################################################################################\n",
      "TensorRT unsupported/non-converted OP Report:\n",
      "\t- NoOp -> 2x\n",
      "\t- Identity -> 1x\n",
      "\t- Placeholder -> 1x\n",
      "--------------------------------------------------------------------------------\n",
      "\t- Total nonconverted OPs: 4\n",
      "\t- Total nonconverted OP Types: 3\n",
      "For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops.\n",
      "################################################################################\n",
      "\n",
      "2022-04-06 22:24:07.492475: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:1281] The environment variable TF_TRT_MAX_ALLOWED_ENGINES=20 has no effect since there are only 1 TRT Engines with  at least minimum_segment_size=3 nodes.\n",
      "2022-04-06 22:24:07.495845: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:795] Number of TensorRT candidate segments: 1\n",
      "2022-04-06 22:24:07.501660: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:909] Replaced segment 0 consisting of 500 nodes by TRTEngineOp_2_0.\n",
      "2022-04-06 22:24:07.601609: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1191] Optimization results for grappler item: tf_graph\n",
      "  model_pruner: Graph size after: 880 nodes (-322), 1535 edges (-322), time = 6.032ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.059ms.\n",
      "  layout: Graph size after: 884 nodes (4), 1539 edges (4), time = 29.394ms.\n",
      "  dependency_optimizer: Graph size after: 560 nodes (-324), 575 edges (-964), time = 9.313ms.\n",
      "  constant_folding: Graph size after: 558 nodes (-2), 573 edges (-2), time = 15.498ms.\n",
      "  common_subgraph_elimination: Graph size after: 508 nodes (-50), 573 edges (0), time = 47.696ms.\n",
      "  TensorRTOptimizer: Graph size after: 9 nodes (-499), 2 edges (-571), time = 243.308ms.\n",
      "  constant_folding: Graph size after: 3 nodes (-6), 2 edges (0), time = 1.146ms.\n",
      "Optimization results for grappler item: TRTEngineOp_2_0_native_segment\n",
      "  model_pruner: Graph size after: 450 nodes (-52), 469 edges (-52), time = 2.721ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.032ms.\n",
      "  layout: Graph size after: 450 nodes (0), 469 edges (0), time = 8.05ms.\n",
      "  dependency_optimizer: Graph size after: 450 nodes (0), 469 edges (0), time = 3.899ms.\n",
      "  constant_folding: Graph size after: 450 nodes (0), 469 edges (0), time = 8.195ms.\n",
      "  common_subgraph_elimination: Graph size after: 450 nodes (0), 469 edges (0), time = 41.535ms.\n",
      "  TensorRTOptimizer: Graph size after: 450 nodes (0), 469 edges (0), time = 0.725ms.\n",
      "  constant_folding: Graph size after: 450 nodes (0), 469 edges (0), time = 8.173ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Could not find TRTEngineOp_2_0 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Assets written to: resnet50_saved_model_TFTRT_FP32/assets\n",
      "Done Converting to TF-TRT FP32\n"
     ]
    }
   ],
   "source": [
    "print('Converting to TF-TRT FP32...')\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir='resnet50_saved_model',\n",
    "                                   precision_mode=trt.TrtPrecisionMode.FP32,\n",
    "                                    max_workspace_size_bytes=1<<33,\n",
    "                                    maximum_cached_engines=2)\n",
    "converter.convert()\n",
    "converter.save(output_saved_model_dir='resnet50_saved_model_TFTRT_FP32')\n",
    "print('Done Converting to TF-TRT FP32')\n",
    "\n",
    "# The network has two input tensors. \n",
    "# We provide two sets of input shapes by input_fn.\n",
    "# def input_fn():\n",
    "#   input_shapes = [[(8, 224, 224, 3)],\n",
    "#                   [(16, 224, 224, 3)],\n",
    "#                   [(32, 224, 224, 3)]]\n",
    "#   for shapes in input_shapes:\n",
    "#     yield [np.zeros(x) for x in shapes]\n",
    "\n",
    "# converter.build(input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched_input shape:  (64, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "batched_input = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n",
    "batched_input = tf.constant(batched_input)\n",
    "print('batched_input shape: ', batched_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 22:26:57.838384: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:446] TRTEngineOp not using explicit QDQ\n",
      "2022-04-06 22:26:58.494968: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:36] TF-TRT Warning: DefaultLogger It is suggested to disable layer timing cache while using AlgorithmSelector. Please refer to the developer guide in https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#builder-layer-timing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: 11.9ms\n",
      "Step 50: 12.4ms\n",
      "Step 100: 12.0ms\n",
      "Step 150: 12.1ms\n",
      "Step 200: 12.0ms\n",
      "Step 250: 12.1ms\n",
      "Step 300: 12.1ms\n",
      "Step 350: 12.0ms\n",
      "Step 400: 12.2ms\n",
      "Step 450: 12.1ms\n",
      "Step 500: 12.1ms\n",
      "Step 550: 12.1ms\n",
      "Step 600: 12.1ms\n",
      "Step 650: 12.1ms\n",
      "Step 700: 12.2ms\n",
      "Step 750: 12.1ms\n",
      "Step 800: 12.1ms\n",
      "Step 850: 12.1ms\n",
      "Step 900: 12.1ms\n",
      "Step 950: 12.1ms\n",
      "Throughput: 5286 images/s\n"
     ]
    }
   ],
   "source": [
    "benchmark_tftrt('resnet50_saved_model_TFTRT_FP32',batched_input,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Colab-TF20-TF-TRT-inference-from-Keras-saved-model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
