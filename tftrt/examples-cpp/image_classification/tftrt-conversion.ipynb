{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dR1W9kv7IPhE"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yb3TdMZAkVNq"
   },
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# TensorFlow C++ Inference with TF-TRT Models\n",
    "\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will download a pretrained Keras ResNet-50 model, optimize it with TF-TRT, convert it to a frozen graph, then load and do inference with the TensorFlow C++ API.\n",
    "\n",
    "First, we download the image net labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!curl -L \"https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz\" | tar -C ./data -xz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Fg4x4aomCY4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LG4IBNn-2PWY"
   },
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pillow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "v0mfnfqg3ned",
    "outputId": "11c043a0-b8e5-49e2-f907-5f1372c92a68",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow version: \", tf.version.VERSION)\n",
    "\n",
    "# check TensorRT version\n",
    "print(\"TensorRT version: \")\n",
    "!dpkg -l | grep nvinfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9U8b2394CZRu"
   },
   "source": [
    "An available TensorRT installation looks like:\n",
    "\n",
    "```\n",
    "TensorRT version: \n",
    "ii  libnvinfer8                       8.2.2-1+cuda11.4                  amd64        TensorRT runtime libraries\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nWYufTjPCMgW"
   },
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yyzwxjlm37jx"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v-R2iN4akVOi"
   },
   "source": [
    "## Data\n",
    "We download several random images for testing from the Internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tVJ2-8rokVOl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mkdir ./data\n",
    "!wget  -O ./data/img0.JPG \"https://d17fnq9dkz9hgj.cloudfront.net/breed-uploads/2018/08/siberian-husky-detail.jpg?bust=1535566590&width=630\"\n",
    "!wget  -O ./data/img1.JPG \"https://www.hakaimagazine.com/wp-content/uploads/header-gulf-birds.jpg\"\n",
    "!wget  -O ./data/img2.JPG \"https://www.artis.nl/media/filer_public_thumbnails/filer_public/00/f1/00f1b6db-fbed-4fef-9ab0-84e944ff11f8/chimpansee_amber_r_1920x1080.jpg__1920x1080_q85_subject_location-923%2C365_subsampling-2.jpg\"\n",
    "!wget  -O ./data/img3.JPG \"https://www.familyhandyman.com/wp-content/uploads/2018/09/How-to-Avoid-Snakes-Slithering-Up-Your-Toilet-shutterstock_780480850.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "F_9n-AR1kVOv",
    "outputId": "e0ead6dc-e761-404e-a030-f6d3057a57da"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "for i in range(4):\n",
    "  img_path = './data/img%d.JPG'%i\n",
    "  img = image.load_img(img_path, target_size=(224, 224),  interpolation='bilinear')\n",
    "  plt.subplot(2,2,i+1)\n",
    "  plt.imshow(img);\n",
    "  plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xeV4r2YTkVO1"
   },
   "source": [
    "## Model\n",
    "\n",
    "We next download and test a ResNet-50 pre-trained model from the Keras model zoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "WwRBOikEkVO3",
    "outputId": "2d63bc46-8bac-492f-b519-9ae5f19176bc"
   },
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "colab_type": "code",
    "id": "lFKQPoLO_ikd",
    "outputId": "c0b93de8-c94b-4977-992e-c780e12a3d52"
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "  img_path = './data/img%d.JPG'%i\n",
    "  img = image.load_img(img_path, target_size=(224, 224),interpolation='bilinear')\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "\n",
    "  preds = model.predict(x)\n",
    "  # decode the results into a list of tuples (class, description, probability)\n",
    "  # (one such list for each sample in the batch)\n",
    "  print('{} - Predicted: {}'.format(img_path, decode_predictions(preds, top=3)[0]))\n",
    "\n",
    "  plt.subplot(2,2,i+1)\n",
    "  plt.imshow(img);\n",
    "  plt.axis('off');\n",
    "  plt.title(decode_predictions(preds, top=3)[0][0][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XrL3FEcdkVPA"
   },
   "source": [
    "TF-TRT takes input as a TensorFlow saved model, therefore, we re-export the Keras model as a TF saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "WxlUF3rlkVPH",
    "outputId": "9f3864e7-f211-4c06-d2d2-585c1a477e34"
   },
   "outputs": [],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "model.save('resnet50_saved_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "colab_type": "code",
    "id": "RBu2RKs6kVPP",
    "outputId": "8e063261-7efb-47fd-fa6c-1bb5076d418c"
   },
   "outputs": [],
   "source": [
    "!saved_model_cli show --all --dir resnet50_saved_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qBQwBvlNm-J8"
   },
   "source": [
    "### Inference with native TF2.0 saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zLN0GMCkVPe"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('resnet50_saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "Fbj-UEOxkVPs",
    "outputId": "3a2b34f9-8034-48cb-b3fe-477f09966025"
   },
   "outputs": [],
   "source": [
    "img_path = './data/img0.JPG'  # Siberian_husky\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('{} - Predicted: {}'.format(img_path, decode_predictions(preds, top=3)[0]))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img);\n",
    "plt.axis('off');\n",
    "plt.title(decode_predictions(preds, top=3)[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CGc-dC6DvwRP",
    "outputId": "e0a22e05-f4fe-47b6-93e8-2b806bf7098a"
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "batched_input = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "for i in range(batch_size):\n",
    "  img_path = './data/img%d.JPG' % (i % 4)\n",
    "  img = image.load_img(img_path, target_size=(224, 224))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  batched_input[i, :] = x\n",
    "batched_input = tf.constant(batched_input)\n",
    "print('batched_input shape: ', batched_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rFBV6hQR7N3z"
   },
   "outputs": [],
   "source": [
    "# Benchmarking throughput\n",
    "N_warmup_run = 50\n",
    "N_run = 1000\n",
    "elapsed_time = []\n",
    "\n",
    "for i in range(N_warmup_run):\n",
    "  preds = model.predict(batched_input)\n",
    "\n",
    "for i in range(N_run):\n",
    "  start_time = time.time()\n",
    "  preds = model.predict(batched_input)\n",
    "  end_time = time.time()\n",
    "  elapsed_time = np.append(elapsed_time, end_time - start_time)\n",
    "  if i % 50 == 0:\n",
    "    print('Step {}: {:4.1f}ms'.format(i, (elapsed_time[-50:].mean()) * 1000))\n",
    "\n",
    "print('Throughput: {:.0f} images/s'.format(N_run * batch_size / elapsed_time.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vC_RN0BAkVPy"
   },
   "source": [
    "### TF-TRT FP32 model\n",
    "\n",
    "We next convert the TF native FP32 model to a TF-TRT FP32 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "0eLImSJ-kVPz",
    "outputId": "e2c353c7-8e4b-49aa-ab97-f4d82797d4d8"
   },
   "outputs": [],
   "source": [
    "print('Converting to TF-TRT FP32...')\n",
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(precision_mode=trt.TrtPrecisionMode.FP32,\n",
    "                                                               max_workspace_size_bytes=8000000000)\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir='resnet50_saved_model',\n",
    "                                    conversion_params=conversion_params)\n",
    "converter.convert()\n",
    "converter.save(output_saved_model_dir='resnet50_saved_model_TFTRT_FP32')\n",
    "print('Done Converting to TF-TRT FP32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "colab_type": "code",
    "id": "dlue_3npkVQC",
    "outputId": "4dd6a366-fe9a-43c8-aad0-dd357bba41bb"
   },
   "outputs": [],
   "source": [
    "!saved_model_cli show --all --dir resnet50_saved_model_TFTRT_FP32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vd2DoGUp8ivj"
   },
   "source": [
    "Next, we load and test the TF-TRT FP32 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.saved_model.load(\"resnet50_saved_model_TFTRT_FP32\", tags=[tag_constants.SERVING]).signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rf97K_rxvwRm"
   },
   "outputs": [],
   "source": [
    "def predict_tftrt(input_saved_model):\n",
    "    \"\"\"Runs prediction on a single image and shows the result.\n",
    "    input_saved_model (string): Name of the input model stored in the current dir\n",
    "    \"\"\"\n",
    "    img_path = './data/img0.JPG'  # Siberian_husky\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    x = tf.constant(x)\n",
    "    \n",
    "    saved_model_loaded = tf.saved_model.load(input_saved_model, tags=[tag_constants.SERVING])\n",
    "    signature_keys = list(saved_model_loaded.signatures.keys())\n",
    "    print(signature_keys)\n",
    "\n",
    "    infer = saved_model_loaded.signatures['serving_default']\n",
    "    print(infer.structured_outputs)\n",
    "\n",
    "    labeling = infer(x)\n",
    "    preds = labeling['predictions'].numpy()\n",
    "    print('{} - Predicted: {}'.format(img_path, decode_predictions(preds, top=3)[0]))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.imshow(img);\n",
    "    plt.axis('off');\n",
    "    plt.title(decode_predictions(preds, top=3)[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "pRK0pRE-snvb",
    "outputId": "1f7ab6c1-dbfa-4e3e-a21d-df9975c70455"
   },
   "outputs": [],
   "source": [
    "predict_tftrt('resnet50_saved_model_TFTRT_FP32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z9b5j6jMvwRt"
   },
   "outputs": [],
   "source": [
    "def benchmark_tftrt(input_saved_model):\n",
    "    saved_model_loaded = tf.saved_model.load(input_saved_model, tags=[tag_constants.SERVING])\n",
    "    infer = saved_model_loaded.signatures['serving_default']\n",
    "\n",
    "    N_warmup_run = 50\n",
    "    N_run = 1000\n",
    "    elapsed_time = []\n",
    "\n",
    "    for i in range(N_warmup_run):\n",
    "      labeling = infer(batched_input)\n",
    "\n",
    "    for i in range(N_run):\n",
    "      start_time = time.time()\n",
    "      labeling = infer(batched_input)\n",
    "      end_time = time.time()\n",
    "      elapsed_time = np.append(elapsed_time, end_time - start_time)\n",
    "      if i % 50 == 0:\n",
    "        print('Step {}: {:4.1f}ms'.format(i, (elapsed_time[-50:].mean()) * 1000))\n",
    "\n",
    "    print('Throughput: {:.0f} images/s'.format(N_run * batch_size / elapsed_time.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ai6bxNcNszHc"
   },
   "outputs": [],
   "source": [
    "benchmark_tftrt('resnet50_saved_model_TFTRT_FP32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model for C++ inference\n",
    "\n",
    "We can see that the TF-TRT FP32 model provide great speedup over the native Keras model. Now let's prepare this model for C++ inference. We will freeze this model and write it's frozen graph to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2mM9D3BTEzQS"
   },
   "outputs": [],
   "source": [
    "# Convert Keras model to ConcreteFunction\n",
    "full_model = tf.function(lambda x: model(x))\n",
    "full_model = full_model.get_concrete_function(\n",
    "    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\n",
    "\n",
    "# Get frozen ConcreteFunction\n",
    "frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "frozen_func.graph.as_graph_def()\n",
    "\n",
    "# Save frozen graph from frozen ConcreteFunction to hard drive\n",
    "tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "                  logdir=\"./frozen_models_trt_fp32\",\n",
    "                  name=\"frozen_models_trt_fp32.pb\",\n",
    "                  as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [op.name for op in frozen_func.graph.get_operations()]\n",
    "print(\"-\" * 50)\n",
    "print(\"Frozen model layers: \")\n",
    "for layer in layers:\n",
    "    print(layer)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"Frozen model inputs: \")\n",
    "print(frozen_func.inputs)\n",
    "print(\"Frozen model outputs: \")\n",
    "print(frozen_func.outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I13snJ9VkVQh"
   },
   "source": [
    "### What's next\n",
    "Refer back to the [Readme](README.md) to load the TF-TRT frozen graph model for inference with the TensorFlow C++ API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Colab-TF20-TF-TRT-inference-from-Keras-saved-model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
